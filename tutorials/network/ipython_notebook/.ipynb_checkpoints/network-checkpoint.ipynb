{
 "metadata": {
  "name": "",
  "signature": "sha256:3cb87330237a8ea1fcfa15bbb09ea795bd8a45a392b34293b18dca5843df8621"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Visualization of the correlation network"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Mirador](http://fathom.info/mirador/) is a software tool for exploratory analysis of complex datasets. It has been developed as a collaboration between Fathom Information Design and the Sabeti Lab at Harvard University.\n",
      "\n",
      "Mirador allows to inspect different kind of plots (scatter, histograms, [eikosograms](http://fathom.info/latest/6246)) between any pairwise combination of variables in the dataset, and also to rank variables according to their [correlation score](http://fathom.info/latest/7028) with a variable of interest. However, it doesn't offer the option to calculate the correlations between all the (selected) variables, which is needed to generate a visual representation of the [correlation matrix](http://www.datavis.ca/papers/corrgram.pdf) of the system and can give an overall image of the dependency structure in the data. To do this, we can export the data of the variables we are interested in, run the correlation matrix calculation in a Python script using [Miralib](https://github.com/mirador/miralib), the underlying library in Mirador that provides all the underlying statistical calculations in Mirador, and then open the correlation matrix with [Gephi](http://gephi.github.io/), or any other software for visualization of network data."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exporting data from Mirador"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will work with the [Diabetes 1999-2008](http://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008#) dataset included in the built-in Mirador examples. If we search for the row variable \"time_in_hospital\", and sort the columns by their correlation with this variable (by clicking on the variable name), we should get the following result in Mirador:\n",
      "\n",
      "<img src=\"diabetes.png\">\n",
      "\n",
      "If we open the profile view, we can select the variables we are interested in to include in out correlation matrix, by dragging the tooltips in the bottom of the plot:\n",
      "\n",
      "<img src=\"diabetes-profile.png\">\n",
      "\n",
      "Now we can export these variables and all the corresponding data by clicking on the \"Export selection\" button on the top right corner of the profile window."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Calculating the correlation matrix"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once we export the profile data, we can do any further calculations on it with other tools for statistical analysis. In our case, we will start by running a Python script that uses the same correlation calculation in Mirador to generate the correlation matrix, which is a NxN matrix where the (i, j) element contains the correlation score between variables i and j in our data. In order to run this calculation, we use Miralib to load the exported profile dataset, and iterate over all variable pairs and calculate the correlation scores. Since Miralib is written in Java, the best way to access it from Python right now is by using [Jython](http://www.jython.org/).\n",
      "\n",
      "The [scripts repository](https://github.com/mirador/scripts) contains all you need to run your own scripts through Jython. You can do it wihtout having to install Jython, since all you need is the jythonlib.jar, miralib.jar and commons-math3-3.2.jar packages. The Miralib API is being documented in [this page](http://fathom.info/mirador/javadoc/).\n",
      "\n",
      "The following Python code will load the exported profile data in ./diabetes/export, and save the resulting correlation matrix to the ./diabetes/network/network.csv file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys, codecs\n",
      "from miralib.utils import Log\n",
      "from miralib.utils import Preferences\n",
      "from miralib.utils import Project\n",
      "from miralib.data import DataRanges\n",
      "from miralib.data import DataSet\n",
      "from miralib.data import Variable\n",
      "from miralib.data import DataSlice2D\n",
      "from miralib.shannon import Similarity\n",
      "\n",
      "Log.init()\n",
      "\n",
      "inputFile = \"./diabetes/export/profile-config.mira\";\n",
      "outputFile = \"./diabetes/network/network.csv\";\n",
      "\n",
      "preferences = Preferences()\n",
      "project = Project(inputFile, preferences)\n",
      "dataset = DataSet(project);\n",
      "ranges = DataRanges();\n",
      "\n",
      "count = dataset.getVariableCount()\n",
      "output = [\"\"] * (count + 1)\n",
      "    \n",
      "print \"Calculating correlation matrix:\"\n",
      "scores = [[0 for x in xrange(count)] for x in xrange(count)] \n",
      "for i in range(0, count):\n",
      "    print \"  Row \" + str(i) + \"/\" + str(count) + \"...\"\n",
      "    for j in range(i, count):\n",
      "        vi = dataset.getVariable(i)\n",
      "        vj = dataset.getVariable(j)\n",
      "        slice = dataset.getSlice(vi, vj, ranges)\n",
      "        score = 0\n",
      "        if i != j and slice.missing < project.missingThreshold():\n",
      "            score = Similarity.calculate(slice, project.pvalue(), project)\n",
      "        scores[i][j] = scores[j][i] = score        \n",
      "print \"Done.\"\n",
      "    \n",
      "header = \"\";\n",
      "for i in range(0, count):\n",
      "    vi = dataset.getVariable(i)\n",
      "    vname = vi.getAlias().replace('\"', '\\'');\n",
      "    header = header + \";\\\"\" + vname + \"\\\"\";\n",
      "output[0] = header;\n",
      "\n",
      "for i in range(0, count):\n",
      "    vi = dataset.getVariable(i)\n",
      "    vname = vi.getAlias().replace('\"', '\\'')\n",
      "    line = \"\\\"\" + vname + \"\\\"\"\n",
      "    for j in range(0, count):\n",
      "        line = line + \";\" + str(scores[i][j])\n",
      "    output[1 + i] = line\n",
      "\n",
      "file = codecs.open(outputFile, \"w\", \"utf-8\")\n",
      "for line in output:\n",
      "    file.write(line + \"\\n\");\n",
      "file.close()    \n",
      "\n",
      "print \"Saved to\",outputFile"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to run this Python using the stand-alone Jython package we provide, you would run the following command from the terminal:\n",
      "\n",
      "```bash\n",
      "java -jar jythonlib.jar network.py\n",
      "```\n",
      "\n",
      "assuming that the Python code is saved in a file named network.py. Once we run this script, we are ready to input the data in Gephi."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Importing data into Gephi"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Gephi is a network visualization and analysis tool. It offers many layouts to represent network data (force atlas, circular, etc.), as well as clustering and other analysis options. Our script save the correlation matrix in [CSV format](http://gephi.github.io/users/supported-graph-formats/csv-format/), which can be imported from Gephi as an undirected, weighted graph: \n",
      "\n",
      "<img src=\"gephi-import.png\">\n",
      "\n",
      "Once we have imported the correlation matrix into Gephi, we can use its interface to calculate the [network modularity](http://en.wikipedia.org/wiki/Modularity_(networks), the [node centrality](http://en.wikipedia.org/wiki/Centrality#Eigenvector_centrality), and filter out edges with low weight:\n",
      "\n",
      "<img src=\"gephi-edit.png\">\n",
      "\n",
      "For our correlation matrix data, we can generate a force-directed layout where we will see two major groups of variables,  first those that correspond to the diagnosis procedures, with admission source ID as the central node, and second the actual laboratory variables, that don't connect directly to time in hospital, but to readmission instead.\n",
      "\n",
      "<img src=\"network-forceatlas.png\">\n",
      "\n",
      "Many other representation are also possible, for example the circular layout, which in this case doesn't seem to be as informartive as the force-directed layout:\n",
      "\n",
      "<img src=\"network-circlelayout.png\">"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}